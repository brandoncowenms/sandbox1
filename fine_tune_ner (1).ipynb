{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "https://huggingface.co/docs/transformers/training\r\n",
        "\r\n",
        "# https://github.com/huggingface/evaluate"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\r\n",
        "\r\n",
        "raw_datasets = load_dataset(\"conll2003\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a57781fa7a714062bda4490f7e83210e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/1.62k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8be77ae862cf4737808c1854291342d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /home/azureuser/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee...\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0d80c8f6f48476f9f79d9aee1f01198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09dbf39b2f364291860411d74b13ddba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/3251 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46927baf3e6048e7a7d157509e535082"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/3454 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be8a783d486d41039c966d7fa07ec658"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset conll2003 downloaded and prepared to /home/azureuser/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee. Subsequent calls will reuse this data.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed4b022694ee4a8684e447d402ed1dcd"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1666186529526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14042\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3251\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3454\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186546287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][0][\"tokens\"]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186553208
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][0][\"ner_tags\"]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186565510
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\r\n",
        "ner_feature"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186575873
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ner_feature.feature.names\r\n",
        "label_names"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186611919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\r\n",
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\r\n",
        "line1 = \"\"\r\n",
        "line2 = \"\"\r\n",
        "for word, label in zip(words, labels):\r\n",
        "    full_label = label_names[label]\r\n",
        "    max_length = max(len(word), len(full_label))\r\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\r\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\r\n",
        "\r\n",
        "print(line1)\r\n",
        "print(line2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "EU    rejects German call to boycott British lamb . \nB-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186614413
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\r\n",
        "\r\n",
        "model_checkpoint = \"bert-base-cased\"\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4c3f10ca7c24a4184056f2956e027a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "261b57f33475453f99688de121103e6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3a7c02404454b769cd85ac9144079f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "666443532dc64482abce07139f5d6f92"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186631460
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186644869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\r\n",
        "inputs.tokens()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "['[CLS]',\n 'EU',\n 'rejects',\n 'German',\n 'call',\n 'to',\n 'boycott',\n 'British',\n 'la',\n '##mb',\n '.',\n '[SEP]']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186689606
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.word_ids()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186702803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\r\n",
        "    new_labels = []\r\n",
        "    current_word = None\r\n",
        "    for word_id in word_ids:\r\n",
        "        if word_id != current_word:\r\n",
        "            # Start of a new word!\r\n",
        "            current_word = word_id\r\n",
        "            label = -100 if word_id is None else labels[word_id]\r\n",
        "            new_labels.append(label)\r\n",
        "        elif word_id is None:\r\n",
        "            # Special token\r\n",
        "            new_labels.append(-100)\r\n",
        "        else:\r\n",
        "            # Same word as previous token\r\n",
        "            label = labels[word_id]\r\n",
        "            # If the label is B-XXX we change it to I-XXX\r\n",
        "            if label % 2 == 1:\r\n",
        "                label += 1\r\n",
        "            new_labels.append(label)\r\n",
        "\r\n",
        "    return new_labels"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186710989
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\r\n",
        "word_ids = inputs.word_ids()\r\n",
        "print(labels)\r\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186717237
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\r\n",
        "    tokenized_inputs = tokenizer(\r\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\r\n",
        "    )\r\n",
        "    all_labels = examples[\"ner_tags\"]\r\n",
        "    new_labels = []\r\n",
        "    for i, labels in enumerate(all_labels):\r\n",
        "        word_ids = tokenized_inputs.word_ids(i)\r\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\r\n",
        "\r\n",
        "    tokenized_inputs[\"labels\"] = new_labels\r\n",
        "    return tokenized_inputs"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186724558
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(\r\n",
        "    tokenize_and_align_labels,\r\n",
        "    batched=True,\r\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Parameter 'function'=<function tokenize_and_align_labels at 0x7f9053cd8430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/15 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56fc642590ee47f39a22bf7189d4376e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "284e4c26f1b246bfb5a06ffa5b2ad32b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e6336a7841453b827c14e23aeea0b5"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186739124
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tune"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\r\n",
        "\r\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186754607
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\r\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n[-100, 1, 2, -100]\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186761504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: seqeval in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.2.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from seqeval) (0.22.1)\nRequirement already satisfied: numpy>=1.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from seqeval) (1.21.6)\nRequirement already satisfied: scipy>=0.17.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.3)\nRequirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (0.14.1)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666186919862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n\u001b[K     |████████████████████████████████| 72 kB 313 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: dill in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (0.3.5.1)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (0.8.1)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (0.70.13)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: datasets>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (2.3.2)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (2022.7.1)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (1.1.5)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (3.0.0)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\nRequirement already satisfied: pyarrow>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (6.0.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->evaluate) (2019.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.3.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187431175
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\r\n",
        "\r\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2373d486167f405da2c93be5117eec1c"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187446717
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\r\n",
        "labels = [label_names[i] for i in labels]\r\n",
        "labels"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187523034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\r\n",
        "labels = [label_names[i] for i in labels]\r\n",
        "labels"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187530340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},\r\n",
        " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\r\n",
        " 'overall_precision': 1.0,\r\n",
        " 'overall_recall': 0.67,\r\n",
        " 'overall_f1': 0.8,\r\n",
        " 'overall_accuracy': 0.89}"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 0.67,\n 'overall_f1': 0.8,\n 'overall_accuracy': 0.89}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187537079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compute metrics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "def compute_metrics(eval_preds):\r\n",
        "    logits, labels = eval_preds\r\n",
        "    predictions = np.argmax(logits, axis=-1)\r\n",
        "\r\n",
        "    # Remove ignored index (special tokens) and convert to labels\r\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\r\n",
        "    true_predictions = [\r\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\r\n",
        "        for prediction, label in zip(predictions, labels)\r\n",
        "    ]\r\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\r\n",
        "    return {\r\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\r\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\r\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\r\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\r\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187557109
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\r\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187564751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\r\n",
        "\r\n",
        "model = AutoModelForTokenClassification.from_pretrained(\r\n",
        "    model_checkpoint,\r\n",
        "    id2label=id2label,\r\n",
        "    label2id=label2id,\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051a9333706a4f528b0e7628822f68b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187590161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.num_labels"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "9"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187590660
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fine tuning model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\r\n",
        "\r\n",
        "args = TrainingArguments(\r\n",
        "    \"bert-finetuned-ner\",\r\n",
        "    evaluation_strategy=\"epoch\",\r\n",
        "    save_strategy=\"epoch\",\r\n",
        "    learning_rate=2e-5,\r\n",
        "    num_train_epochs=3,\r\n",
        "    weight_decay=0.01\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666187674020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model=model,\r\n",
        "    args=args,\r\n",
        "    train_dataset=tokenized_datasets[\"train\"],\r\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\r\n",
        "    data_collator=data_collator,\r\n",
        "    compute_metrics=compute_metrics,\r\n",
        "    tokenizer=tokenizer,\r\n",
        ")\r\n",
        "trainer.train()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5268/5268 23:15, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.085900</td>\n      <td>0.067699</td>\n      <td>0.914000</td>\n      <td>0.937227</td>\n      <td>0.925467</td>\n      <td>0.983031</td>\n      <td>26.625700</td>\n      <td>122.100000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.043200</td>\n      <td>0.059282</td>\n      <td>0.932549</td>\n      <td>0.946988</td>\n      <td>0.939713</td>\n      <td>0.985960</td>\n      <td>26.831000</td>\n      <td>121.166000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.020400</td>\n      <td>0.063377</td>\n      <td>0.938589</td>\n      <td>0.951700</td>\n      <td>0.945099</td>\n      <td>0.986534</td>\n      <td>26.759100</td>\n      <td>121.491000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Attempted to log scalar metric loss:\n0.2519\nAttempted to log scalar metric learning_rate:\n1.810174639331815e-05\nAttempted to log scalar metric epoch:\n0.28\nAttempted to log scalar metric loss:\n0.1046\nAttempted to log scalar metric learning_rate:\n1.6203492786636296e-05\nAttempted to log scalar metric epoch:\n0.57\nAttempted to log scalar metric loss:\n0.0859\nAttempted to log scalar metric learning_rate:\n1.4305239179954442e-05\nAttempted to log scalar metric epoch:\n0.85\nAttempted to log scalar metric eval_loss:\n0.06769903749227524\nAttempted to log scalar metric eval_precision:\n0.9139996717544724\nAttempted to log scalar metric eval_recall:\n0.93722652305621\nAttempted to log scalar metric eval_f1:\n0.9254673867885335\nAttempted to log scalar metric eval_accuracy:\n0.9830311414611174\nAttempted to log scalar metric eval_runtime:\n26.6257\nAttempted to log scalar metric eval_samples_per_second:\n122.1\nAttempted to log scalar metric epoch:\n1.0\nAttempted to log scalar metric loss:\n0.0596\nAttempted to log scalar metric learning_rate:\n1.240698557327259e-05\nAttempted to log scalar metric epoch:\n1.14\nAttempted to log scalar metric loss:\n0.0433\nAttempted to log scalar metric learning_rate:\n1.0508731966590738e-05\nAttempted to log scalar metric epoch:\n1.42\nAttempted to log scalar metric loss:\n0.0394\nAttempted to log scalar metric learning_rate:\n8.610478359908885e-06\nAttempted to log scalar metric epoch:\n1.71\nAttempted to log scalar metric loss:\n0.0432\nAttempted to log scalar metric learning_rate:\n6.712224753227031e-06\nAttempted to log scalar metric epoch:\n1.99\nAttempted to log scalar metric eval_loss:\n0.05928191542625427\nAttempted to log scalar metric eval_precision:\n0.9325488896254558\nAttempted to log scalar metric eval_recall:\n0.9469875462807136\nAttempted to log scalar metric eval_f1:\n0.9397127588510356\nAttempted to log scalar metric eval_accuracy:\n0.9859598516512628\nAttempted to log scalar metric eval_runtime:\n26.831\nAttempted to log scalar metric eval_samples_per_second:\n121.166\nAttempted to log scalar metric epoch:\n2.0\nAttempted to log scalar metric loss:\n0.0257\nAttempted to log scalar metric learning_rate:\n4.8139711465451785e-06\nAttempted to log scalar metric epoch:\n2.28\nAttempted to log scalar metric loss:\n0.0213\nAttempted to log scalar metric learning_rate:\n2.9157175398633257e-06\nAttempted to log scalar metric epoch:\n2.56\nAttempted to log scalar metric loss:\n0.0204\nAttempted to log scalar metric learning_rate:\n1.0174639331814731e-06\nAttempted to log scalar metric epoch:\n2.85\nAttempted to log scalar metric eval_loss:\n0.06337723135948181\nAttempted to log scalar metric eval_precision:\n0.9385892116182573\nAttempted to log scalar metric eval_recall:\n0.9516997643890945\nAttempted to log scalar metric eval_f1:\n0.9450990223113561\nAttempted to log scalar metric eval_accuracy:\n0.9865338199799847\nAttempted to log scalar metric eval_runtime:\n26.7591\nAttempted to log scalar metric eval_samples_per_second:\n121.491\nAttempted to log scalar metric epoch:\n3.0\nAttempted to log scalar metric train_runtime:\n1400.3298\nAttempted to log scalar metric train_samples_per_second:\n3.762\nAttempted to log scalar metric total_flos:\n1164936503332224.0\nAttempted to log scalar metric epoch:\n3.0\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "TrainOutput(global_step=5268, training_loss=0.06689404300785282, metrics={'train_runtime': 1400.3298, 'train_samples_per_second': 3.762, 'total_flos': 1164936503332224.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 696442880, 'init_mem_gpu_alloc_delta': 431435264, 'init_mem_cpu_peaked_delta': 308211712, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 114716672, 'train_mem_gpu_alloc_delta': 1300622336, 'train_mem_cpu_peaked_delta': 179138560, 'train_mem_gpu_peaked_delta': 1224142336})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666189108173
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}